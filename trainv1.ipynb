{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "828a9dff-37d3-46d7-be33-634fd5f4a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db61658d-ca66-4c4d-9a4a-ebd58425bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/lambda/lab/Metadata_v2\"\n",
    "key_met = [line.strip() for line in open(\"meta.txt\")]\n",
    "def load_meta(N = 17, par = key_met):\n",
    "    df = pd.read_csv(\"db_sample_201901221525.csv\")\n",
    "    Y = []\n",
    "    X = []\n",
    "    for file in os.listdir(PATH):\n",
    "        lo = file.split(\".\")[0] + \".jpg\"\n",
    "        val = df.loc[df[\"imagename\"]==lo, \"ane_glo\"].iloc[0]\n",
    "        dictdata  = np.load(os.path.join(PATH,file), allow_pickle=True)[()]\n",
    "        if len(dictdata)<N:\n",
    "            print(\"Ah kgon\")\n",
    "            continue\n",
    "        Y.append(val)\n",
    "        #print(file, val, type(dictdata))\n",
    "        aux = []\n",
    "        for i in range(N):\n",
    "            nn = dictdata[i]\n",
    "            for j in par:\n",
    "            #aux.extend(nn[\"Per\"].reshape(-1,).tolist())\n",
    "                aux.extend(nn[j].reshape(-1,).tolist())\n",
    "\n",
    "        \n",
    "        X.append(aux)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f6887-5117-4896-ba5b-1a6f2775215a",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aad16dc4-b2c5-4b15-ae5f-9ecc3db021e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rgb_mean',\n",
       " 'rgb_per',\n",
       " 'rgb_mo',\n",
       " 'hsv_mean',\n",
       " 'hsv_per',\n",
       " 'hsv_mo',\n",
       " 'lab_mean',\n",
       " 'lab_std',\n",
       " 'lab_per',\n",
       " 'lab_mo',\n",
       " 'x_mean',\n",
       " 'x_std',\n",
       " 'y_mean',\n",
       " 'y_std']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e33b408-126c-439b-93f6-9f382ba23771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N menor a 17\n"
     ]
    }
   ],
   "source": [
    "N = 17\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "PATH = \"/home/lambda/lab/Metadata_v2\"\n",
    "key_met = [line.strip() for line in open(\"meta.txt\")]\n",
    "df = pd.read_csv(\"db_sample_201901221525.csv\")\n",
    "Y = []\n",
    "X = []\n",
    "for file in os.listdir(PATH):\n",
    "    lo = file.split(\".\")[0] + \".jpg\"\n",
    "    val = df.loc[df[\"imagename\"]==lo, \"ane_glo\"].iloc[0]\n",
    "    dictdata  = np.load(os.path.join(PATH,file), allow_pickle=True)[()]\n",
    "    if len(dictdata)<N:\n",
    "        print(\"N menor a %d\"% N)\n",
    "        continue\n",
    "    Y.append(val)\n",
    "    #print(file, val, type(dictdata))\n",
    "    aux = []\n",
    "    for i in range(17):\n",
    "        nn = dictdata[i]\n",
    "        aux.append(nn['rgb_mo'][0]) #R\n",
    "        aux.append(nn['rgb_mo'][1]) #G\n",
    "        aux.append(nn['hsv_mo'][2]) #V\n",
    "        aux.append(nn['lab_mo'][0]) #L\n",
    "        aux.append(nn['lab_mo'][1]) #A\n",
    "\n",
    "\n",
    "    X.append(aux)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acd73aff-b899-4135-ac6d-40e88268efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(Y)\n",
    "#X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bd83336-7a86-4a1f-8972-edcbd65df5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 2).all(axis=1)\n",
    "new_X = X[filtered_entries]\n",
    "new_y = y[filtered_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f614407d-ab04-4c12-9247-4361b8ac904c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f008881f-4c1d-4f7d-ae5a-12d1ba334f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((445, 85), (445,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape, new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90c91dd3-9fea-459a-8c14-d0355e5524a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR = X[:, 0::5]\n",
    "GG = X[:, 1::5]\n",
    "VV = X[:, 2::5]\n",
    "LL = X[:, 3::5]\n",
    "AA = X[:, 4::5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ef3aee2-2896-4edc-9d84-79a4d2045a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246.0, 3.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(RR)), np.min(np.min(RR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acea3a2b-e2ab-4ba6-b6c5-02c3ce816e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239.0, 1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(GG)), np.min(np.min(GG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23d63b8b-d3c4-4147-9900-3115cb5b102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95.521880088973, 1.8589241082328378)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(VV)), np.min(np.min(VV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c10ff8e3-afe6-433c-be79-5614d8bbd672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54.04592674064895, -44.77588537545274)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(LL)), np.min(np.min(LL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84eca8cf-5bdb-4c4a-bddc-3f11f77fc141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.251074021172826, -8.592354761726927)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.max(AA)), np.min(np.min(AA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4784335-696a-421b-9d63-5137782e81e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8e383f68-2c47-4025-8101-39b93967d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:10<00:00,  3.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>-1.21</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-1.28</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>-2.51</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-2.65</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-10.07</td>\n",
       "      <td>-4.04</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-13.85</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-135.57</td>\n",
       "      <td>-61.16</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>-164.55</td>\n",
       "      <td>-74.35</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>-164.58</td>\n",
       "      <td>-74.36</td>\n",
       "      <td>13.19</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-527.86</td>\n",
       "      <td>-239.70</td>\n",
       "      <td>23.57</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>-582.55</td>\n",
       "      <td>-264.59</td>\n",
       "      <td>24.76</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-689.99</td>\n",
       "      <td>-313.49</td>\n",
       "      <td>26.94</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GeneralizedLinearRegressor</th>\n",
       "      <td>-755.47</td>\n",
       "      <td>-343.29</td>\n",
       "      <td>28.19</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>-755.47</td>\n",
       "      <td>-343.29</td>\n",
       "      <td>28.19</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-883.44</td>\n",
       "      <td>-401.54</td>\n",
       "      <td>30.48</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>-1279.84</td>\n",
       "      <td>-581.95</td>\n",
       "      <td>36.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-1971.35</td>\n",
       "      <td>-896.67</td>\n",
       "      <td>45.52</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-2278.53</td>\n",
       "      <td>-1036.48</td>\n",
       "      <td>48.94</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>-2466.64</td>\n",
       "      <td>-1122.09</td>\n",
       "      <td>50.92</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-3708.87</td>\n",
       "      <td>-1687.46</td>\n",
       "      <td>62.43</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>-4032.16</td>\n",
       "      <td>-1834.61</td>\n",
       "      <td>65.09</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-4099.16</td>\n",
       "      <td>-1865.10</td>\n",
       "      <td>65.63</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-4846.09</td>\n",
       "      <td>-2205.05</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>-4846.09</td>\n",
       "      <td>-2205.05</td>\n",
       "      <td>71.36</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>-10239.83</td>\n",
       "      <td>-4659.89</td>\n",
       "      <td>103.73</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>-10248.42</td>\n",
       "      <td>-4663.80</td>\n",
       "      <td>103.77</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-10436.77</td>\n",
       "      <td>-4749.52</td>\n",
       "      <td>104.72</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>-21228.96</td>\n",
       "      <td>-9661.36</td>\n",
       "      <td>149.35</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-96426.22</td>\n",
       "      <td>-43885.75</td>\n",
       "      <td>318.29</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>-599834.13</td>\n",
       "      <td>-273000.89</td>\n",
       "      <td>793.84</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-803607.26</td>\n",
       "      <td>-365743.79</td>\n",
       "      <td>918.84</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared   RMSE  \\\n",
       "Model                                                                 \n",
       "HuberRegressor                              -1.06       0.06   1.47   \n",
       "LinearSVR                                   -1.09       0.05   1.48   \n",
       "AdaBoostRegressor                           -1.21      -0.01   1.53   \n",
       "SVR                                         -1.27      -0.03   1.54   \n",
       "NuSVR                                       -1.28      -0.04   1.55   \n",
       "XGBRegressor                                -1.59      -0.18   1.65   \n",
       "GradientBoostingRegressor                   -2.51      -0.60   1.92   \n",
       "DecisionTreeRegressor                       -2.65      -0.66   1.96   \n",
       "RANSACRegressor                            -10.07      -4.04   3.41   \n",
       "PassiveAggressiveRegressor                 -13.85      -5.76   3.95   \n",
       "GaussianProcessRegressor                  -135.57     -61.16  11.98   \n",
       "LarsCV                                    -164.55     -74.35  13.19   \n",
       "LassoLarsIC                               -164.55     -74.35  13.19   \n",
       "LassoLarsCV                               -164.55     -74.35  13.19   \n",
       "LassoCV                                   -164.55     -74.35  13.19   \n",
       "LassoLars                                 -164.55     -74.35  13.19   \n",
       "DummyRegressor                            -164.55     -74.35  13.19   \n",
       "ElasticNetCV                              -164.55     -74.35  13.19   \n",
       "BayesianRidge                             -164.58     -74.36  13.19   \n",
       "PoissonRegressor                          -527.86    -239.70  23.57   \n",
       "OrthogonalMatchingPursuitCV               -582.55    -264.59  24.76   \n",
       "MLPRegressor                              -689.99    -313.49  26.94   \n",
       "GeneralizedLinearRegressor                -755.47    -343.29  28.19   \n",
       "TweedieRegressor                          -755.47    -343.29  28.19   \n",
       "ElasticNet                                -883.44    -401.54  30.48   \n",
       "OrthogonalMatchingPursuit                -1279.84    -581.95  36.68   \n",
       "Lasso                                    -1971.35    -896.67  45.52   \n",
       "SGDRegressor                             -2278.53   -1036.48  48.94   \n",
       "RidgeCV                                  -2466.64   -1122.09  50.92   \n",
       "KernelRidge                              -3708.87   -1687.46  62.43   \n",
       "BaggingRegressor                         -4032.16   -1834.61  65.09   \n",
       "Ridge                                    -4099.16   -1865.10  65.63   \n",
       "LinearRegression                         -4846.09   -2205.05  71.36   \n",
       "TransformedTargetRegressor               -4846.09   -2205.05  71.36   \n",
       "LGBMRegressor                           -10239.83   -4659.89 103.73   \n",
       "ExtraTreesRegressor                     -10248.42   -4663.80 103.77   \n",
       "HistGradientBoostingRegressor           -10436.77   -4749.52 104.72   \n",
       "RandomForestRegressor                   -21228.96   -9661.36 149.35   \n",
       "KNeighborsRegressor                     -96426.22  -43885.75 318.29   \n",
       "Lars                                   -599834.13 -273000.89 793.84   \n",
       "ExtraTreeRegressor                     -803607.26 -365743.79 918.84   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "HuberRegressor                       0.27  \n",
       "LinearSVR                            0.10  \n",
       "AdaBoostRegressor                    0.21  \n",
       "SVR                                  0.09  \n",
       "NuSVR                                0.08  \n",
       "XGBRegressor                         0.28  \n",
       "GradientBoostingRegressor            0.97  \n",
       "DecisionTreeRegressor                0.11  \n",
       "RANSACRegressor                      0.42  \n",
       "PassiveAggressiveRegressor           0.02  \n",
       "GaussianProcessRegressor             0.09  \n",
       "LarsCV                               0.19  \n",
       "LassoLarsIC                          0.09  \n",
       "LassoLarsCV                          0.28  \n",
       "LassoCV                              0.75  \n",
       "LassoLars                            0.02  \n",
       "DummyRegressor                       0.01  \n",
       "ElasticNetCV                         0.63  \n",
       "BayesianRidge                        0.06  \n",
       "PoissonRegressor                     0.07  \n",
       "OrthogonalMatchingPursuitCV          0.03  \n",
       "MLPRegressor                         1.10  \n",
       "GeneralizedLinearRegressor           0.05  \n",
       "TweedieRegressor                     0.02  \n",
       "ElasticNet                           0.05  \n",
       "OrthogonalMatchingPursuit            0.01  \n",
       "Lasso                                0.06  \n",
       "SGDRegressor                         0.04  \n",
       "RidgeCV                              0.05  \n",
       "KernelRidge                          0.05  \n",
       "BaggingRegressor                     0.26  \n",
       "Ridge                                0.04  \n",
       "LinearRegression                     0.04  \n",
       "TransformedTargetRegressor           0.03  \n",
       "LGBMRegressor                        0.16  \n",
       "ExtraTreesRegressor                  0.74  \n",
       "HistGradientBoostingRegressor        0.63  \n",
       "RandomForestRegressor                2.27  \n",
       "KNeighborsRegressor                  0.05  \n",
       "Lars                                 0.09  \n",
       "ExtraTreeRegressor                   0.03  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state =123)\n",
    "reg = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None )\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaab6f6-5765-4e69-a474-79a64b834e29",
   "metadata": {},
   "source": [
    "## OUTLIERS DEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e404c8af-fd4f-463a-83ac-85457625899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dattta = np.append(new_X, new_y.reshape(-1, 1), axis = 1)\n",
    "df = pd.DataFrame(dattta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "240fcbf0-8adb-49bc-9119-9873299e0905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 86)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dattta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7af6fc6-6a10-472d-a390-ce3fb5d81b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>49.03</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>31.34</td>\n",
       "      <td>7.70</td>\n",
       "      <td>4.86</td>\n",
       "      <td>...</td>\n",
       "      <td>90.00</td>\n",
       "      <td>43.41</td>\n",
       "      <td>12.06</td>\n",
       "      <td>5.46</td>\n",
       "      <td>86.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>44.46</td>\n",
       "      <td>15.49</td>\n",
       "      <td>6.22</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>49.56</td>\n",
       "      <td>5.73</td>\n",
       "      <td>15.59</td>\n",
       "      <td>41.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>28.53</td>\n",
       "      <td>30.14</td>\n",
       "      <td>12.85</td>\n",
       "      <td>...</td>\n",
       "      <td>67.00</td>\n",
       "      <td>40.60</td>\n",
       "      <td>32.46</td>\n",
       "      <td>16.42</td>\n",
       "      <td>67.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>43.82</td>\n",
       "      <td>38.36</td>\n",
       "      <td>16.64</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>33.02</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>0.76</td>\n",
       "      <td>106.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>49.20</td>\n",
       "      <td>13.53</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>143.00</td>\n",
       "      <td>59.47</td>\n",
       "      <td>17.70</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>143.00</td>\n",
       "      <td>152.00</td>\n",
       "      <td>63.30</td>\n",
       "      <td>12.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>0.27</td>\n",
       "      <td>53.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>19.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>44.00</td>\n",
       "      <td>26.22</td>\n",
       "      <td>30.77</td>\n",
       "      <td>3.54</td>\n",
       "      <td>38.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>28.74</td>\n",
       "      <td>35.29</td>\n",
       "      <td>6.19</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>45.40</td>\n",
       "      <td>3.03</td>\n",
       "      <td>12.75</td>\n",
       "      <td>80.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>43.02</td>\n",
       "      <td>19.73</td>\n",
       "      <td>9.52</td>\n",
       "      <td>...</td>\n",
       "      <td>79.00</td>\n",
       "      <td>43.70</td>\n",
       "      <td>24.70</td>\n",
       "      <td>10.54</td>\n",
       "      <td>85.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>46.81</td>\n",
       "      <td>25.64</td>\n",
       "      <td>6.92</td>\n",
       "      <td>14.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>101.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>44.22</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>2.48</td>\n",
       "      <td>31.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>23.55</td>\n",
       "      <td>24.46</td>\n",
       "      <td>6.12</td>\n",
       "      <td>...</td>\n",
       "      <td>65.00</td>\n",
       "      <td>35.23</td>\n",
       "      <td>40.74</td>\n",
       "      <td>10.75</td>\n",
       "      <td>48.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>36.17</td>\n",
       "      <td>21.51</td>\n",
       "      <td>5.65</td>\n",
       "      <td>12.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>48.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>22.02</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.72</td>\n",
       "      <td>57.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>33.77</td>\n",
       "      <td>17.58</td>\n",
       "      <td>8.04</td>\n",
       "      <td>...</td>\n",
       "      <td>85.00</td>\n",
       "      <td>45.32</td>\n",
       "      <td>24.32</td>\n",
       "      <td>9.71</td>\n",
       "      <td>82.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>45.86</td>\n",
       "      <td>21.05</td>\n",
       "      <td>12.31</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>116.00</td>\n",
       "      <td>113.00</td>\n",
       "      <td>49.23</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>108.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>47.26</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>140.00</td>\n",
       "      <td>59.08</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>117.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>53.85</td>\n",
       "      <td>15.84</td>\n",
       "      <td>1.75</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>105.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>44.83</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>1.30</td>\n",
       "      <td>113.00</td>\n",
       "      <td>119.00</td>\n",
       "      <td>50.72</td>\n",
       "      <td>6.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>146.00</td>\n",
       "      <td>61.11</td>\n",
       "      <td>6.32</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>137.00</td>\n",
       "      <td>142.00</td>\n",
       "      <td>60.52</td>\n",
       "      <td>7.72</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>54.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>24.38</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6.83</td>\n",
       "      <td>71.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>19.52</td>\n",
       "      <td>8.31</td>\n",
       "      <td>...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>17.89</td>\n",
       "      <td>13.91</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>35.19</td>\n",
       "      <td>29.83</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2     3     4      5      6     7     8     9   ...  \\\n",
       "0   114.00  92.00 49.03 -2.86  0.00  63.00  65.00 31.34  7.70  4.86  ...   \n",
       "1   110.00  81.00 49.56  5.73 15.59  41.00  45.00 28.53 30.14 12.85  ...   \n",
       "2    78.00  72.00 33.02 -2.29  0.76 106.00 120.00 49.20 13.53 -3.50  ...   \n",
       "3    66.00  59.00 28.00 -1.76  0.27  53.00  64.00 28.23 19.24  0.21  ...   \n",
       "4   100.00  75.00 45.40  3.03 12.75  80.00  83.00 43.02 19.73  9.52  ...   \n",
       "..     ...    ...   ...   ...   ...    ...    ...   ...   ...   ...  ...   \n",
       "440 101.00  92.00 44.22 -0.38  2.48  31.00  44.00 23.55 24.46  6.12  ...   \n",
       "441  48.00  39.00 22.02  1.76  4.72  57.00  63.00 33.77 17.58  8.04  ...   \n",
       "442 116.00 113.00 49.23 -1.31  0.00 108.00 110.00 47.26  4.87  0.66  ...   \n",
       "443 105.00  99.00 44.83 -1.86  1.30 113.00 119.00 50.72  6.08  0.06  ...   \n",
       "444  54.00  40.00 24.38  1.25  6.83  71.00  70.00 36.15 19.52  8.31  ...   \n",
       "\n",
       "        76    77    78    79     80     81    82    83    84    85  \n",
       "0    90.00 43.41 12.06  5.46  86.00  92.00 44.46 15.49  6.22 12.60  \n",
       "1    67.00 40.60 32.46 16.42  67.00  73.00 43.82 38.36 16.64 11.30  \n",
       "2   143.00 59.47 17.70 -1.41 143.00 152.00 63.30 12.78  0.98 12.50  \n",
       "3    44.00 26.22 30.77  3.54  38.00  56.00 28.74 35.29  6.19 13.10  \n",
       "4    79.00 43.70 24.70 10.54  85.00  94.00 46.81 25.64  6.92 14.40  \n",
       "..     ...   ...   ...   ...    ...    ...   ...   ...   ...   ...  \n",
       "440  65.00 35.23 40.74 10.75  48.00  64.00 36.17 21.51  5.65 12.40  \n",
       "441  85.00 45.32 24.32  9.71  82.00  85.00 45.86 21.05 12.31 11.40  \n",
       "442 140.00 59.08  3.81  0.54 117.00 125.00 53.85 15.84  1.75 13.10  \n",
       "443 146.00 61.11  6.32 -0.26 137.00 142.00 60.52  7.72  1.61 12.10  \n",
       "444  60.00 36.15 17.89 13.91  50.00  56.00 35.19 29.83 11.48 13.10  \n",
       "\n",
       "[445 rows x 86 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6e90fbf-8b98-4ea6-87fc-bc09ac906bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdo = df[(df>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6234363-ce61-4dd5-921d-21332b0db2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdo = fdo.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4ea5aa0-8e4d-4b5e-a5b4-cb4bd1ee8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>49.56</td>\n",
       "      <td>5.73</td>\n",
       "      <td>15.59</td>\n",
       "      <td>41.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>28.53</td>\n",
       "      <td>30.14</td>\n",
       "      <td>12.85</td>\n",
       "      <td>...</td>\n",
       "      <td>67.00</td>\n",
       "      <td>40.60</td>\n",
       "      <td>32.46</td>\n",
       "      <td>16.42</td>\n",
       "      <td>67.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>43.82</td>\n",
       "      <td>38.36</td>\n",
       "      <td>16.64</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>45.40</td>\n",
       "      <td>3.03</td>\n",
       "      <td>12.75</td>\n",
       "      <td>80.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>43.02</td>\n",
       "      <td>19.73</td>\n",
       "      <td>9.52</td>\n",
       "      <td>...</td>\n",
       "      <td>79.00</td>\n",
       "      <td>43.70</td>\n",
       "      <td>24.70</td>\n",
       "      <td>10.54</td>\n",
       "      <td>85.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>46.81</td>\n",
       "      <td>25.64</td>\n",
       "      <td>6.92</td>\n",
       "      <td>14.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111.00</td>\n",
       "      <td>87.00</td>\n",
       "      <td>49.78</td>\n",
       "      <td>5.92</td>\n",
       "      <td>11.66</td>\n",
       "      <td>37.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>24.50</td>\n",
       "      <td>25.86</td>\n",
       "      <td>11.68</td>\n",
       "      <td>...</td>\n",
       "      <td>67.00</td>\n",
       "      <td>38.46</td>\n",
       "      <td>34.48</td>\n",
       "      <td>12.60</td>\n",
       "      <td>86.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>47.92</td>\n",
       "      <td>22.55</td>\n",
       "      <td>11.95</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>36.22</td>\n",
       "      <td>6.08</td>\n",
       "      <td>14.02</td>\n",
       "      <td>56.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>31.07</td>\n",
       "      <td>18.58</td>\n",
       "      <td>8.03</td>\n",
       "      <td>...</td>\n",
       "      <td>129.00</td>\n",
       "      <td>60.46</td>\n",
       "      <td>15.34</td>\n",
       "      <td>9.76</td>\n",
       "      <td>123.00</td>\n",
       "      <td>121.00</td>\n",
       "      <td>58.16</td>\n",
       "      <td>17.55</td>\n",
       "      <td>10.01</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>10.61</td>\n",
       "      <td>46.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>26.57</td>\n",
       "      <td>20.63</td>\n",
       "      <td>10.24</td>\n",
       "      <td>...</td>\n",
       "      <td>69.00</td>\n",
       "      <td>40.86</td>\n",
       "      <td>21.87</td>\n",
       "      <td>11.07</td>\n",
       "      <td>53.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>38.05</td>\n",
       "      <td>33.03</td>\n",
       "      <td>15.43</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>102.00</td>\n",
       "      <td>84.00</td>\n",
       "      <td>46.80</td>\n",
       "      <td>3.52</td>\n",
       "      <td>11.53</td>\n",
       "      <td>107.00</td>\n",
       "      <td>106.00</td>\n",
       "      <td>51.72</td>\n",
       "      <td>19.60</td>\n",
       "      <td>9.58</td>\n",
       "      <td>...</td>\n",
       "      <td>66.00</td>\n",
       "      <td>41.11</td>\n",
       "      <td>28.78</td>\n",
       "      <td>11.17</td>\n",
       "      <td>93.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>50.52</td>\n",
       "      <td>23.87</td>\n",
       "      <td>10.78</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>84.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>40.44</td>\n",
       "      <td>2.30</td>\n",
       "      <td>13.60</td>\n",
       "      <td>58.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>30.28</td>\n",
       "      <td>15.34</td>\n",
       "      <td>11.76</td>\n",
       "      <td>...</td>\n",
       "      <td>72.00</td>\n",
       "      <td>41.68</td>\n",
       "      <td>25.01</td>\n",
       "      <td>11.41</td>\n",
       "      <td>77.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.63</td>\n",
       "      <td>13.04</td>\n",
       "      <td>12.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>89.00</td>\n",
       "      <td>74.00</td>\n",
       "      <td>41.87</td>\n",
       "      <td>4.95</td>\n",
       "      <td>11.34</td>\n",
       "      <td>78.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>40.12</td>\n",
       "      <td>15.38</td>\n",
       "      <td>10.28</td>\n",
       "      <td>...</td>\n",
       "      <td>93.00</td>\n",
       "      <td>50.21</td>\n",
       "      <td>29.28</td>\n",
       "      <td>14.83</td>\n",
       "      <td>118.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>56.21</td>\n",
       "      <td>21.03</td>\n",
       "      <td>12.45</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>48.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>22.02</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.72</td>\n",
       "      <td>57.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>33.77</td>\n",
       "      <td>17.58</td>\n",
       "      <td>8.04</td>\n",
       "      <td>...</td>\n",
       "      <td>85.00</td>\n",
       "      <td>45.32</td>\n",
       "      <td>24.32</td>\n",
       "      <td>9.71</td>\n",
       "      <td>82.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>45.86</td>\n",
       "      <td>21.05</td>\n",
       "      <td>12.31</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>54.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>24.38</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6.83</td>\n",
       "      <td>71.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>19.52</td>\n",
       "      <td>8.31</td>\n",
       "      <td>...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>17.89</td>\n",
       "      <td>13.91</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>35.19</td>\n",
       "      <td>29.83</td>\n",
       "      <td>11.48</td>\n",
       "      <td>13.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4      5      6     7     8     9   ...     76  \\\n",
       "1   110.00 81.00 49.56 5.73 15.59  41.00  45.00 28.53 30.14 12.85  ...  67.00   \n",
       "4   100.00 75.00 45.40 3.03 12.75  80.00  83.00 43.02 19.73  9.52  ...  79.00   \n",
       "8   111.00 87.00 49.78 5.92 11.66  37.00  39.00 24.50 25.86 11.68  ...  67.00   \n",
       "9    74.00 55.00 36.22 6.08 14.02  56.00  60.00 31.07 18.58  8.03  ... 129.00   \n",
       "10   70.00 54.00 34.00 3.04 10.61  46.00  49.00 26.57 20.63 10.24  ...  69.00   \n",
       "..     ...   ...   ...  ...   ...    ...    ...   ...   ...   ...  ...    ...   \n",
       "434 102.00 84.00 46.80 3.52 11.53 107.00 106.00 51.72 19.60  9.58  ...  66.00   \n",
       "435  84.00 64.00 40.44 2.30 13.60  58.00  51.00 30.28 15.34 11.76  ...  72.00   \n",
       "439  89.00 74.00 41.87 4.95 11.34  78.00  76.00 40.12 15.38 10.28  ...  93.00   \n",
       "441  48.00 39.00 22.02 1.76  4.72  57.00  63.00 33.77 17.58  8.04  ...  85.00   \n",
       "444  54.00 40.00 24.38 1.25  6.83  71.00  70.00 36.15 19.52  8.31  ...  60.00   \n",
       "\n",
       "       77    78    79     80     81    82    83    84    85  \n",
       "1   40.60 32.46 16.42  67.00  73.00 43.82 38.36 16.64 11.30  \n",
       "4   43.70 24.70 10.54  85.00  94.00 46.81 25.64  6.92 14.40  \n",
       "8   38.46 34.48 12.60  86.00  84.00 47.92 22.55 11.95 12.90  \n",
       "9   60.46 15.34  9.76 123.00 121.00 58.16 17.55 10.01 11.30  \n",
       "10  40.86 21.87 11.07  53.00  61.00 38.05 33.03 15.43 13.50  \n",
       "..    ...   ...   ...    ...    ...   ...   ...   ...   ...  \n",
       "434 41.11 28.78 11.17  93.00  98.00 50.52 23.87 10.78 11.90  \n",
       "435 41.68 25.01 11.41  77.00  72.00 41.63 20.63 13.04 12.10  \n",
       "439 50.21 29.28 14.83 118.00 110.00 56.21 21.03 12.45 10.00  \n",
       "441 45.32 24.32  9.71  82.00  85.00 45.86 21.05 12.31 11.40  \n",
       "444 36.15 17.89 13.91  50.00  56.00 35.19 29.83 11.48 13.10  \n",
       "\n",
       "[190 rows x 86 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19722ea-ce86-482d-86fd-b53aa0b82a49",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63282b94-91bb-46a1-a20c-e41bcb921d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.array(fdo.values)\n",
    "X = val[:, :-1]\n",
    "y = val[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4407264f-09db-48b9-8e66-b269b49714ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190, 85), (190,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0caa4ae7-0d27-4b53-88ec-501ae5fd529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  0.,  0., 14., 23., 38., 46., 40., 19.,  7.]),\n",
       " array([ 7.8 ,  8.49,  9.18,  9.87, 10.56, 11.25, 11.94, 12.63, 13.32,\n",
       "        14.01, 14.7 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a2352ef-af55-4808-a375-eedbff3dbf47",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-468d799d5990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_root_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lab/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "              'degree':[3, 4, 5, 6],\n",
    "             'C':[0.01, 0.1, 1.0, 10.0]}\n",
    "\n",
    "model = SVR()\n",
    "clf = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error', n_jobs=8)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a3ec2-c967-45be-a6bb-bd97ebd1bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451026f3-b1dd-46d8-825f-e4ac96c2ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(clf.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b828e80-83a7-4531-994a-cd700ce9dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result[\"rank_test_score\"]<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69dcbf-1281-4e0f-b4a9-5b9c3c115cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf84aa-d2e3-457c-9555-80d68e4ceb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd22bfe-0b04-4a80-be09-b33d89bd0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41acc2a-0666-4c40-a1cf-387112a9e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabbf20-decd-46b5-a3db-2ca197aee5e2",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f23d0906-c572-4bcb-8ffe-084b30542615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_alpha',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "parameters = {'alpha':[0.02, 0.024, 0.025, 0.026, 0.03]}\n",
    "model = linear_model.Lasso(max_iter=3000)\n",
    "clf = GridSearchCV(model, parameters, scoring='r2')\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "sorted(clf.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb38f7-d2ad-4410-8ff3-59f654b0ed17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "19b016e7-47f7-4d6c-a016-cd2f6f44ace0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54ad2f-e812-4bb8-97ba-6f66a7c4971c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ea443dd5-b22c-48cd-8069-0b9ed61199aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.02}</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>{'alpha': 0.024}</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.025}</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.026}</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'alpha': 0.03}</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0           0.08          0.02             0.00            0.00        0.02   \n",
       "1           0.05          0.01             0.00            0.00        0.02   \n",
       "2           0.07          0.02             0.00            0.00        0.03   \n",
       "3           0.05          0.01             0.00            0.00        0.03   \n",
       "4           0.05          0.02             0.00            0.00        0.03   \n",
       "\n",
       "             params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 0.02}              -0.88              -0.15              -2.09   \n",
       "1  {'alpha': 0.024}              -0.80              -0.11              -1.95   \n",
       "2  {'alpha': 0.025}              -0.79              -0.10              -1.92   \n",
       "3  {'alpha': 0.026}              -0.77              -0.09              -1.88   \n",
       "4   {'alpha': 0.03}              -0.70              -0.06              -1.75   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0              -0.56              -0.56            -0.85            0.67   \n",
       "1              -0.48              -0.52            -0.77            0.63   \n",
       "2              -0.46              -0.51            -0.75            0.62   \n",
       "3              -0.45              -0.50            -0.74            0.61   \n",
       "4              -0.41              -0.47            -0.68            0.58   \n",
       "\n",
       "   rank_test_score  \n",
       "0                5  \n",
       "1                4  \n",
       "2                3  \n",
       "3                2  \n",
       "4                1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(clf.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1c60a-d878-4cc1-a460-7f116487e4db",
   "metadata": {},
   "source": [
    "# BayessianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56ff6eb7-d3fe-4e2c-8616-b0c3afc0f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_lambda_1',\n",
       " 'param_lambda_2',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "parameters = {'lambda_1':[1e-6, 1e-5, 1e-4, 0.001, 0.01],\n",
    "             'lambda_2':[1e-6, 1e-5, 1e-4, 0.001, 0.01],\n",
    "}\n",
    "model = linear_model.BayesianRidge()\n",
    "clf = GridSearchCV(model, parameters, scoring='r2')\n",
    "clf.fit(X, y)\n",
    "\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9dfc2075-16f1-43a4-b913-a19b7d9ca348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lambda_1</th>\n",
       "      <th>param_lambda_2</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-06, 'lambda_2': 1e-06}</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-06, 'lambda_2': 1e-05}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-06, 'lambda_2': 0.0001}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-06, 'lambda_2': 0.001}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'lambda_1': 1e-06, 'lambda_2': 0.01}</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-05, 'lambda_2': 1e-06}</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-05, 'lambda_2': 1e-05}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-05, 'lambda_2': 0.0001}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 1e-05, 'lambda_2': 0.001}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'lambda_1': 1e-05, 'lambda_2': 0.01}</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.0001, 'lambda_2': 1e-06}</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.0001, 'lambda_2': 1e-05}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.0001, 'lambda_2': 0.0001}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.0001, 'lambda_2': 0.001}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'lambda_1': 0.0001, 'lambda_2': 0.01}</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.001, 'lambda_2': 1e-06}</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.001, 'lambda_2': 1e-05}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.001, 'lambda_2': 0.0001}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.001, 'lambda_2': 0.001}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'lambda_1': 0.001, 'lambda_2': 0.01}</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.01, 'lambda_2': 1e-06}</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.01, 'lambda_2': 1e-05}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.01, 'lambda_2': 0.0001}</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>{'lambda_1': 0.01, 'lambda_2': 0.001}</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'lambda_1': 0.01, 'lambda_2': 0.01}</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0            0.04          0.01             0.00            0.00   \n",
       "1            0.02          0.01             0.00            0.00   \n",
       "2            0.01          0.00             0.00            0.00   \n",
       "3            0.01          0.00             0.00            0.00   \n",
       "4            0.01          0.00             0.00            0.00   \n",
       "5            0.01          0.00             0.00            0.00   \n",
       "6            0.01          0.00             0.00            0.00   \n",
       "7            0.01          0.00             0.00            0.00   \n",
       "8            0.01          0.00             0.00            0.00   \n",
       "9            0.01          0.00             0.00            0.00   \n",
       "10           0.02          0.00             0.00            0.00   \n",
       "11           0.01          0.00             0.00            0.00   \n",
       "12           0.01          0.00             0.00            0.00   \n",
       "13           0.01          0.00             0.00            0.00   \n",
       "14           0.01          0.00             0.00            0.00   \n",
       "15           0.02          0.00             0.00            0.00   \n",
       "16           0.01          0.00             0.00            0.00   \n",
       "17           0.01          0.00             0.00            0.00   \n",
       "18           0.01          0.00             0.00            0.00   \n",
       "19           0.01          0.00             0.00            0.00   \n",
       "20           0.02          0.02             0.00            0.00   \n",
       "21           0.02          0.00             0.00            0.00   \n",
       "22           0.01          0.00             0.00            0.00   \n",
       "23           0.02          0.00             0.00            0.00   \n",
       "24           0.02          0.01             0.00            0.00   \n",
       "\n",
       "   param_lambda_1 param_lambda_2                                    params  \\\n",
       "0            0.00           0.00    {'lambda_1': 1e-06, 'lambda_2': 1e-06}   \n",
       "1            0.00           0.00    {'lambda_1': 1e-06, 'lambda_2': 1e-05}   \n",
       "2            0.00           0.00   {'lambda_1': 1e-06, 'lambda_2': 0.0001}   \n",
       "3            0.00           0.00    {'lambda_1': 1e-06, 'lambda_2': 0.001}   \n",
       "4            0.00           0.01     {'lambda_1': 1e-06, 'lambda_2': 0.01}   \n",
       "5            0.00           0.00    {'lambda_1': 1e-05, 'lambda_2': 1e-06}   \n",
       "6            0.00           0.00    {'lambda_1': 1e-05, 'lambda_2': 1e-05}   \n",
       "7            0.00           0.00   {'lambda_1': 1e-05, 'lambda_2': 0.0001}   \n",
       "8            0.00           0.00    {'lambda_1': 1e-05, 'lambda_2': 0.001}   \n",
       "9            0.00           0.01     {'lambda_1': 1e-05, 'lambda_2': 0.01}   \n",
       "10           0.00           0.00   {'lambda_1': 0.0001, 'lambda_2': 1e-06}   \n",
       "11           0.00           0.00   {'lambda_1': 0.0001, 'lambda_2': 1e-05}   \n",
       "12           0.00           0.00  {'lambda_1': 0.0001, 'lambda_2': 0.0001}   \n",
       "13           0.00           0.00   {'lambda_1': 0.0001, 'lambda_2': 0.001}   \n",
       "14           0.00           0.01    {'lambda_1': 0.0001, 'lambda_2': 0.01}   \n",
       "15           0.00           0.00    {'lambda_1': 0.001, 'lambda_2': 1e-06}   \n",
       "16           0.00           0.00    {'lambda_1': 0.001, 'lambda_2': 1e-05}   \n",
       "17           0.00           0.00   {'lambda_1': 0.001, 'lambda_2': 0.0001}   \n",
       "18           0.00           0.00    {'lambda_1': 0.001, 'lambda_2': 0.001}   \n",
       "19           0.00           0.01     {'lambda_1': 0.001, 'lambda_2': 0.01}   \n",
       "20           0.01           0.00     {'lambda_1': 0.01, 'lambda_2': 1e-06}   \n",
       "21           0.01           0.00     {'lambda_1': 0.01, 'lambda_2': 1e-05}   \n",
       "22           0.01           0.00    {'lambda_1': 0.01, 'lambda_2': 0.0001}   \n",
       "23           0.01           0.00     {'lambda_1': 0.01, 'lambda_2': 0.001}   \n",
       "24           0.01           0.01      {'lambda_1': 0.01, 'lambda_2': 0.01}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                0.08               0.07              -0.15   \n",
       "1                0.09               0.09              -0.17   \n",
       "2                0.09               0.13              -0.24   \n",
       "3                0.11               0.18              -0.33   \n",
       "4                0.04               0.16              -0.47   \n",
       "5                0.08               0.07              -0.15   \n",
       "6                0.09               0.09              -0.17   \n",
       "7                0.09               0.13              -0.24   \n",
       "8                0.11               0.18              -0.33   \n",
       "9                0.04               0.16              -0.47   \n",
       "10               0.08               0.07              -0.15   \n",
       "11               0.09               0.09              -0.17   \n",
       "12               0.09               0.13              -0.24   \n",
       "13               0.11               0.18              -0.33   \n",
       "14               0.04               0.16              -0.47   \n",
       "15               0.08               0.07              -0.15   \n",
       "16               0.09               0.09              -0.17   \n",
       "17               0.09               0.13              -0.24   \n",
       "18               0.11               0.18              -0.33   \n",
       "19               0.04               0.16              -0.47   \n",
       "20               0.08               0.07              -0.15   \n",
       "21               0.09               0.09              -0.17   \n",
       "22               0.09               0.13              -0.24   \n",
       "23               0.11               0.18              -0.33   \n",
       "24               0.04               0.16              -0.47   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0               -0.04               0.00            -0.01            0.09   \n",
       "1               -0.05               0.01            -0.01            0.10   \n",
       "2               -0.08               0.00            -0.02            0.13   \n",
       "3               -0.10              -0.05            -0.04            0.18   \n",
       "4               -0.08              -0.18            -0.11            0.22   \n",
       "5               -0.04               0.00            -0.01            0.09   \n",
       "6               -0.05               0.01            -0.01            0.10   \n",
       "7               -0.08               0.00            -0.02            0.13   \n",
       "8               -0.10              -0.05            -0.04            0.18   \n",
       "9               -0.08              -0.18            -0.11            0.22   \n",
       "10              -0.04               0.00            -0.01            0.09   \n",
       "11              -0.05               0.01            -0.01            0.10   \n",
       "12              -0.08               0.00            -0.02            0.13   \n",
       "13              -0.10              -0.05            -0.04            0.18   \n",
       "14              -0.08              -0.18            -0.11            0.22   \n",
       "15              -0.04               0.00            -0.01            0.09   \n",
       "16              -0.05               0.01            -0.01            0.10   \n",
       "17              -0.08               0.00            -0.02            0.13   \n",
       "18              -0.10              -0.05            -0.04            0.18   \n",
       "19              -0.08              -0.18            -0.11            0.22   \n",
       "20              -0.04               0.00            -0.01            0.09   \n",
       "21              -0.05               0.01            -0.01            0.10   \n",
       "22              -0.08               0.00            -0.02            0.13   \n",
       "23              -0.10              -0.05            -0.04            0.18   \n",
       "24              -0.08              -0.18            -0.11            0.22   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 6  \n",
       "1                 5  \n",
       "2                15  \n",
       "3                20  \n",
       "4                25  \n",
       "5                 7  \n",
       "6                 4  \n",
       "7                14  \n",
       "8                19  \n",
       "9                24  \n",
       "10                8  \n",
       "11                3  \n",
       "12               13  \n",
       "13               18  \n",
       "14               23  \n",
       "15                9  \n",
       "16                2  \n",
       "17               12  \n",
       "18               17  \n",
       "19               22  \n",
       "20               10  \n",
       "21                1  \n",
       "22               11  \n",
       "23               16  \n",
       "24               21  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(clf.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bff792-570d-47b5-8d88-f5c294ff15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82f403-8e84-4c4d-804c-016e44e5a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9ef9f-c2cd-42d6-895c-1f8e8d02aaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af8239-4391-4c6e-a56b-6742a7cb1a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace73ca-d3c9-4050-aaaa-6f6e4ba3be3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e350499-22d4-4b85-a9c4-9a0abd3c060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6b912-9a05-4671-ab22-8592b6f55b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5aa0e-65c0-4fa5-b0f2-377aa3bd638a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e089040-64b8-4bb6-9b74-9c3077dbc52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a58ad-1a9e-4ec2-a5b3-080496dcae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569031e7-7518-4e9c-bce6-3476165a68dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ba8f2-213a-449a-b9ea-6589c967c731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d734131-50d5-4b4c-bcf0-ab8cd12a9b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
